name: Auto-Scrape News Every 30 Minutes

on:
  schedule:
    - cron: '*/30 * * * *' # Every 30 minutes
  workflow_dispatch: # Manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ü§ñ Scrape News with Retry Logic
        run: |
          echo "üöÄ Starting scrape at $(date)"
          
          # Retry configuration
          MAX_RETRIES=3
          RETRY_DELAY=10
          
          for i in $(seq 1 $MAX_RETRIES); do
            echo "üîÑ Attempt $i of $MAX_RETRIES"
            
            response=$(curl -s -w "\n%{http_code}" -X POST \
              --max-time 300 \
              --connect-timeout 30 \
              "https://yccsnkufqiutfiaiqvrr.supabase.co/functions/v1/scrape-news" \
              -H "Authorization: Bearer ${{ secrets.SUPABASE_ANON_KEY }}" \
              -H "Content-Type: application/json")
            
            http_code=$(echo "$response" | tail -n1)
            body=$(echo "$response" | head -n-1)
            
            echo "üìä Response Code: $http_code"
            echo "üìÑ Response Body: $body"
            
            if [ "$http_code" = "200" ]; then
              echo "‚úÖ Success on attempt $i!"
              exit 0
            else
              echo "‚ö†Ô∏è Failed with HTTP $http_code. Retrying in ${RETRY_DELAY}s..."
              if [ $i -lt $MAX_RETRIES ]; then
                sleep $RETRY_DELAY
                RETRY_DELAY=$((RETRY_DELAY * 2))
              fi
            fi
          done
          
          echo "‚ùå Failed after $MAX_RETRIES attempts"
          exit 1
